# models/hmm_model.py
import os
import sys
import pickle
import nltk
from nltk.tag import hmm

# ThÃªm Ä‘Æ°á»ng dáº«n
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

class HMMTagger:
    def __init__(self, model_path=None):
        """
        HMM Tagger (khÃ´ng xá»­ lÃ½ OOV)
        """
        self.model = None
        self.model_loaded = False
        self.vocab = set()
        
        if model_path is None:
            # TÃ¬m file model tá»± Ä‘á»™ng
            model_path = self._find_model_file()
        
        self._load_model(model_path)
    
    def _find_model_file(self):
        """TÃ¬m file HMM model"""
        possible_paths = [
            "saved_models/hmm_model.joblib",  # Joblib format
            "saved_models/hmm_model.pkl",     # Pickle format  
            "saved_models/hmm.pkl",           # TÃªn cÅ©
            "saved_models/hmm.joblib",
            os.path.join("models", "saved_models", "hmm_model.joblib"),
            "hmm_model.joblib",
            "hmm.pkl"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                print(f"âœ… Found HMM model: {path}")
                return path
        
        print("âŒ No HMM model file found")
        return None
    
    def _load_model(self, model_path):
        """Load HMM model tá»« file"""
        if model_path and os.path.exists(model_path):
            try:
                # Thá»­ load vá»›i joblib trÆ°á»›c
                try:
                    import joblib
                    self.model = joblib.load(model_path)
                    print("âœ… Loaded HMM model with joblib")
                except:
                    # Thá»­ load vá»›i pickle
                    with open(model_path, 'rb') as f:
                        self.model = pickle.load(f)
                    print("âœ… Loaded HMM model with pickle")
                
                self.model_loaded = True
                
                # Extract vocab tá»« model náº¿u cÃ³
                if hasattr(self.model, 'vocab'):
                    self.vocab = self.model.vocab
                elif hasattr(self.model, '_symbols'):
                    self.vocab = set(self.model._symbols)
                
                print(f"   Model type: {type(self.model)}")
                print(f"   Vocab size: {len(self.vocab)}" if self.vocab else "   No vocab found")
                
            except Exception as e:
                print(f"âŒ Failed to load HMM model: {e}")
                self.model = None
        else:
            print("âš ï¸ HMM model file not found")
    
    def _preprocess_tokens(self, tokens):
        """Tiá»n xá»­ lÃ½ tokens cho HMM"""
        processed = []
        for token in tokens:
            if not token:
                continue
            
            # Xá»­ lÃ½ contractions cÆ¡ báº£n
            lower_token = token.lower()
            if lower_token == "i'm":
                processed.extend(["I", "'m"])
            elif lower_token in ["you're", "he's", "she's", "it's", "we're", "they're"]:
                processed.extend([token[:-3], "'s"])
            elif lower_token in ["i'll", "you'll", "he'll", "she'll", "it'll", "we'll", "they'll"]:
                processed.extend([token[:-4], "'ll"])
            elif lower_token in ["i'd", "you'd", "he'd", "she'd", "it'd", "we'd", "they'd"]:
                processed.extend([token[:-3], "'d"])
            elif lower_token in ["i've", "you've", "we've", "they've"]:
                processed.extend([token[:-4], "'ve"])
            else:
                processed.append(token)
        
        return processed
    
    def tag(self, tokens):
        """GÃ¡n nhÃ£n POS cho tokens"""
        if not tokens:
            return []
        
        # Náº¿u khÃ´ng cÃ³ model, dÃ¹ng fallback
        if not self.model_loaded or self.model is None:
            print("âš ï¸ HMM model not available, using fallback")
            return self._fallback_tag(tokens)
        
        try:
            # Tiá»n xá»­ lÃ½ tokens
            processed_tokens = self._preprocess_tokens(tokens)
            
            # HMM tagging
            tagged = self.model.tag(processed_tokens)
            
            # Extract tags
            tags = [tag for _, tag in tagged]
            
            # Náº¿u sá»‘ tags khÃ¡c sá»‘ tokens (do xá»­ lÃ½ contractions)
            if len(tags) != len(tokens):
                # Map back
                if len(processed_tokens) > len(tokens):
                    # ÄÃ£ tÃ¡ch contractions
                    original_tags = []
                    proc_idx = 0
                    for token in tokens:
                        lower_token = token.lower()
                        if lower_token in ["i'm", "you're", "he's", "she's", "it's", "we're", "they're",
                                         "i'll", "you'll", "he'll", "she'll", "it'll", "we'll", "they'll",
                                         "i'd", "you'd", "he'd", "she'd", "it'd", "we'd", "they'd",
                                         "i've", "you've", "we've", "they've"]:
                            # Láº¥y tag cá»§a tá»« Ä‘áº§u tiÃªn trong contraction
                            original_tags.append(tags[proc_idx])
                            proc_idx += 2  # Bá» qua contraction part
                        else:
                            original_tags.append(tags[proc_idx])
                            proc_idx += 1
                    tags = original_tags
            
            print(f"âœ… HMM model predicted {len(tags)} tags")
            return tags
            
        except Exception as e:
            print(f"âŒ HMM prediction error: {e}")
            return self._fallback_tag(tokens)
    
    def _fallback_tag(self, tokens):
        """Rule-based fallback tagging"""
        tags = []
        for token in tokens:
            if not token:
                tags.append("X")
                continue
                
            lower_token = token.lower()
            
            if token == "I":
                tags.append("PRON")
            elif lower_token in ['the', 'a', 'an', 'this', 'that']:
                tags.append("DET")
            elif lower_token in ['i', 'you', 'he', 'she', 'it', 'we', 'they']:
                tags.append("PRON")
            elif lower_token in ['is', 'am', 'are', 'was', 'were', 'be', 'been']:
                tags.append("VERB")
            elif token.endswith('ing'):
                tags.append("VERB")
            elif token.endswith('ly'):
                tags.append("ADV")
            elif token[0].isupper() and len(token) > 1:
                tags.append("PROPN")
            elif any(c.isdigit() for c in token):
                tags.append("NUM")
            else:
                tags.append("NOUN")
        
        return tags


# Test function
def test_hmm_tagger():
    """Test HMM tagger"""
    print("\nğŸ§ª Testing HMM Tagger...")
    tagger = HMMTagger()
    
    if tagger.model_loaded:
        print("âœ… Model loaded successfully")
        
        test_sentences = [
            "I love natural language processing",
            "The quick brown fox jumps",
            "Google is a company",
        ]
        
        for sentence in test_sentences:
            print(f"\nğŸ“ Sentence: {sentence}")
            tokens = sentence.split()
            tags = tagger.tag(tokens)
            
            for token, tag in zip(tokens, tags):
                print(f"   {token:15} -> {tag}")
    else:
        print("âŒ Model not loaded")

if __name__ == "__main__":
    test_hmm_tagger()