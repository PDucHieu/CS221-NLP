# models/hmm_oov_model.py
import os
import sys
import pickle
import nltk
from nltk.tag import hmm

# Th√™m ƒë∆∞·ªùng d·∫´n
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

class HMMOOVTagger:
    def __init__(self, model_path=None):
        """
        HMM Tagger v·ªõi x·ª≠ l√Ω OOV (Out-Of-Vocabulary)
        """
        self.model = None
        self.model_loaded = False
        self.vocab = set()
        self.OOV_TOKEN = "__OOV__"
        
        if model_path is None:
            # T√¨m file model t·ª± ƒë·ªông
            model_path = self._find_model_file()
        
        self._load_model(model_path)
    
    def _find_model_file(self):
        """T√¨m file HMM OOV model"""
        possible_paths = [
            "saved_models/hmm_oov_model.joblib",  # Joblib format
            "saved_models/hmm_oov_model.pkl",     # Pickle format
            "saved_models/hmm_oov.pkl",           # T√™n c≈©
            "saved_models/hmm_oov.joblib",
            os.path.join("models", "saved_models", "hmm_oov_model.joblib"),
            "hmm_oov_model.joblib",
            "hmm_oov.pkl"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                print(f"‚úÖ Found HMM-OOV model: {path}")
                return path
        
        print("‚ùå No HMM-OOV model file found")
        return None
    
    def _load_model(self, model_path):
        """Load HMM OOV model t·ª´ file"""
        if model_path and os.path.exists(model_path):
            try:
                # Th·ª≠ load v·ªõi joblib tr∆∞·ªõc
                try:
                    import joblib
                    loaded_data = joblib.load(model_path)
                    print("‚úÖ Loaded HMM-OOV model with joblib")
                except:
                    # Th·ª≠ load v·ªõi pickle
                    with open(model_path, 'rb') as f:
                        loaded_data = pickle.load(f)
                    print("‚úÖ Loaded HMM-OOV model with pickle")
                
                # X·ª≠ l√Ω d·ªØ li·ªáu ƒë√£ load
                if isinstance(loaded_data, tuple) and len(loaded_data) == 2:
                    # Format: (model, vocab)
                    self.model, self.vocab = loaded_data
                elif hasattr(loaded_data, 'tag'):  # Ch·ªâ c√≥ model
                    self.model = loaded_data
                    # C·ªë g·∫Øng extract vocab
                    if hasattr(self.model, 'vocab'):
                        self.vocab = self.model.vocab
                    elif hasattr(self.model, '_symbols'):
                        self.vocab = set(self.model._symbols)
                else:
                    self.model = loaded_data
                    self.vocab = set()
                
                self.model_loaded = True
                
                print(f"   Model type: {type(self.model)}")
                print(f"   Vocab size: {len(self.vocab)}" if self.vocab else "   No vocab found")
                print(f"   OOV token: {self.OOV_TOKEN}")
                
            except Exception as e:
                print(f"‚ùå Failed to load HMM-OOV model: {e}")
                self.model = None
        else:
            print("‚ö†Ô∏è HMM-OOV model file not found")
    
    def _preprocess_tokens(self, tokens):
        """Ti·ªÅn x·ª≠ l√Ω tokens v√† x·ª≠ l√Ω OOV"""
        processed = []
        
        for token in tokens:
            if not token:
                continue
            
            # X·ª≠ l√Ω contractions c∆° b·∫£n
            lower_token = token.lower()
            contraction_parts = None
            
            if lower_token == "i'm":
                contraction_parts = ["I", "'m"]
            elif lower_token in ["you're", "he's", "she's", "it's", "we're", "they're"]:
                contraction_parts = [token[:-3], "'s"]
            elif lower_token in ["i'll", "you'll", "he'll", "she'll", "it'll", "we'll", "they'll"]:
                contraction_parts = [token[:-4], "'ll"]
            elif lower_token in ["i'd", "you'd", "he'd", "she'd", "it'd", "we'd", "they'd"]:
                contraction_parts = [token[:-3], "'d"]
            elif lower_token in ["i've", "you've", "we've", "they've"]:
                contraction_parts = [token[:-4], "'ve"]
            
            if contraction_parts:
                # X·ª≠ l√Ω OOV cho t·ª´ng ph·∫ßn c·ªßa contraction
                for part in contraction_parts:
                    if self.vocab and part.lower() not in self.vocab and part not in ["'m", "'s", "'re", "'ll", "'d", "'ve"]:
                        processed.append(self.OOV_TOKEN)
                    else:
                        processed.append(part)
            else:
                # Ki·ªÉm tra OOV
                if self.vocab and token.lower() not in self.vocab:
                    processed.append(self.OOV_TOKEN)
                else:
                    processed.append(token)
        
        return processed
    
    def _replace_oov_words(self, tokens, vocab, oov_token="__OOV__"):
        """Thay th·∫ø t·ª´ OOV b·∫±ng OOV token"""
        replaced = []
        for token in tokens:
            if token.lower() in vocab or token in ["'m", "'s", "'re", "'ll", "'d", "'ve"]:
                replaced.append(token)
            else:
                replaced.append(oov_token)
        return replaced
    
    def tag(self, tokens):
        """G√°n nh√£n POS v·ªõi x·ª≠ l√Ω OOV"""
        if not tokens:
            return []
        
        # N·∫øu kh√¥ng c√≥ model, d√πng fallback
        if not self.model_loaded or self.model is None:
            print("‚ö†Ô∏è HMM-OOV model not available, using fallback")
            return self._fallback_tag(tokens)
        
        try:
            # Ti·ªÅn x·ª≠ l√Ω tokens v√† x·ª≠ l√Ω OOV
            processed_tokens = self._preprocess_tokens(tokens)
            
            # N·∫øu c√≥ vocab, th·ª±c hi·ªán OOV replacement th√™m l·∫ßn n·ªØa ƒë·ªÉ ch·∫Øc ch·∫Øn
            if self.vocab:
                processed_tokens = self._replace_oov_words(processed_tokens, self.vocab, self.OOV_TOKEN)
            
            # HMM tagging
            tagged = self.model.tag(processed_tokens)
            
            # Extract tags
            tags = [tag for _, tag in tagged]
            
            # Map tags tr·ªü l·∫°i tokens g·ªëc
            final_tags = []
            proc_idx = 0
            
            for token in tokens:
                lower_token = token.lower()
                
                # Ki·ªÉm tra n·∫øu token l√† contraction
                if lower_token in ["i'm", "you're", "he's", "she's", "it's", "we're", "they're",
                                 "i'll", "you'll", "he'll", "she'll", "it'll", "we'll", "they'll",
                                 "i'd", "you'd", "he'd", "she'd", "it'd", "we'd", "they'd",
                                 "i've", "you've", "we've", "they've"]:
                    # L·∫•y tag c·ªßa ph·∫ßn ƒë·∫ßu contraction
                    if proc_idx < len(tags):
                        final_tags.append(tags[proc_idx])
                    else:
                        final_tags.append("NOUN")
                    proc_idx += 2  # B·ªè qua contraction part
                else:
                    # Token th√¥ng th∆∞·ªùng
                    if proc_idx < len(tags):
                        final_tags.append(tags[proc_idx])
                    else:
                        final_tags.append("NOUN")
                    proc_idx += 1
            
            print(f"‚úÖ HMM-OOV model predicted {len(final_tags)} tags")
            print(f"   OOV replacements: {processed_tokens.count(self.OOV_TOKEN)}")
            
            return final_tags
            
        except Exception as e:
            print(f"‚ùå HMM-OOV prediction error: {e}")
            return self._fallback_tag(tokens)
    
    def _fallback_tag(self, tokens):
        """Rule-based fallback tagging v·ªõi OOV handling"""
        tags = []
        for token in tokens:
            if not token:
                tags.append("X")
                continue
                
            lower_token = token.lower()
            
            # OOV detection ƒë∆°n gi·∫£n
            if self.vocab and token.lower() not in self.vocab:
                # T·ª´ OOV, d√πng heuristic
                if token.endswith('ing'):
                    tags.append("VERB")
                elif token.endswith('ly'):
                    tags.append("ADV")
                elif token[0].isupper():
                    tags.append("PROPN")
                elif any(c.isdigit() for c in token):
                    tags.append("NUM")
                else:
                    tags.append("NOUN")
            else:
                # T·ª´ trong vocab
                if token == "I":
                    tags.append("PRON")
                elif lower_token in ['the', 'a', 'an', 'this', 'that']:
                    tags.append("DET")
                elif lower_token in ['i', 'you', 'he', 'she', 'it', 'we', 'they']:
                    tags.append("PRON")
                elif lower_token in ['is', 'am', 'are', 'was', 'were']:
                    tags.append("VERB")
                elif token.endswith('ing'):
                    tags.append("VERB")
                elif token.endswith('ly'):
                    tags.append("ADV")
                elif token[0].isupper():
                    tags.append("PROPN")
                elif any(c.isdigit() for c in token):
                    tags.append("NUM")
                else:
                    tags.append("NOUN")
        
        return tags


# Test function
def test_hmm_oov_tagger():
    """Test HMM-OOV tagger"""
    print("\nüß™ Testing HMM-OOV Tagger...")
    tagger = HMMOOVTagger()
    
    if tagger.model_loaded:
        print("‚úÖ Model loaded successfully")
        
        # Test v·ªõi t·ª´ OOV v√† contractions
        test_sentences = [
            "I'm the one who shall grid",  # "grid" c√≥ th·ªÉ l√† OOV
            "The quixotic fox jumps blithely",  # "quixotic" v√† "blithely" c√≥ th·ªÉ l√† OOV
            "Google is a zylophone company",  # "zylophone" l√† OOV
        ]
        
        for sentence in test_sentences:
            print(f"\nüìù Sentence: {sentence}")
            tokens = sentence.split()
            tags = tagger.tag(tokens)
            
            print("   Results:")
            for token, tag in zip(tokens, tags):
                is_oov = tagger.vocab and token.lower() not in tagger.vocab
                oov_marker = " (OOV)" if is_oov else ""
                print(f"     '{token:15}' -> {tag}{oov_marker}")
    else:
        print("‚ùå Model not loaded")

if __name__ == "__main__":
    test_hmm_oov_tagger()